import scrapy
from datetime import date
import csv
import os

class EcomSpider(scrapy.Spider):
    name = "scrapy4_bnw"

    start_urls = ['https://www.belezanaweb.com.br/busca/?q=creme%20facial']

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.data = []
        self.file_name = date.today().strftime('%d_%m_%Y_dados_belezanaweb.csv')

    def parse(self, response):
        # Itera sobre cada item na página de resultados
        for product in response.css('.showcase-item'):
            try:
                def parse_price(price_str):
                    if price_str:
                        price_str = price_str.replace('.', '').replace(',', '.')
                        return float(price_str)
                    return None

                price_full = product.css('.item-price-max::text').get()
                price_full = parse_price(price_full.split(' ')[1]) if price_full else None

                if price_full is None:
                    continue  # Se price_full é nulo, exclui este item e passa para o próximo

                price_soft = product.css('.price-value::text').get()
                price_soft = parse_price(price_soft.split(' ')[1]) if price_soft else None

                review_count = product.css('div.showcase-item-rating.pointer::attr(title)').get()
                if review_count:
                    review_count = review_count.split()[0]
                    if review_count.lower() == "avalie":
                        review_count = 0
                    else:
                        review_count = int(review_count)
                else:
                    review_count = 0

                rating = product.css('img.star::attr(alt)').get()
                if rating:
                    rating = parse_price(rating.split(' ')[1])
                else:
                    rating = 0.0

                if price_full and price_soft:
                    priceoff = round(((price_soft / price_full) - 1) * (-100))
                else:
                    priceoff = None

                def format_price(price):
                    if price is not None:
                        return f"{price:.2f}".replace('.', ',')
                    return None

                price_full = format_price(price_full)
                price_soft = format_price(price_soft)
                rating = format_price(rating)

            except Exception as e:
                self.log(f"Error parsing item: {e}")
                continue

            self.data.append({
                'Date': date.today().strftime('%d/%m/%Y'),
                'Brand': product.css('.showcase-item-brand::text').get().strip(),
                'Title': product.css('.showcase-item-title::text').get().strip(),
                'price_full': price_full,
                'price_soft': price_soft,
                'priceoff': priceoff,
                'Rating': rating,
                'Review Count': review_count,
            })

        next_page = response.css('.btn-load-more::attr(data-ajax)').get()
        if next_page:
            next_page = response.urljoin(next_page)
            yield scrapy.Request(next_page, callback=self.parse)

    def close(self, reason):
        # Caminho base onde os arquivos serão salvos
        base_path = './bases_historicas'

        # Cria a pasta 'bases_historicas' se não existir
        if not os.path.exists(base_path):
            os.makedirs(base_path)
            self.log(f"Directory created: {base_path}")

        # Define o caminho completo do arquivo
        file_path = os.path.join(base_path, self.file_name)

        # Salva os dados no arquivo CSV
        keys = self.data[0].keys() if self.data else []
        with open(file_path, 'w', newline='', encoding='utf-8') as file:
            writer = csv.DictWriter(file, fieldnames=keys)
            writer.writeheader()
            writer.writerows(self.data)

        self.log(f"Data saved to {file_path}")
